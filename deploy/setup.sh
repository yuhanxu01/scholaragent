#!/bin/bash
# ScholarMind éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬
# è‡ªåŠ¨è®¾ç½®ç¯å¢ƒå˜é‡ã€æ•°æ®åº“ã€Redisç­‰

set -e

echo "ğŸ“ ScholarMind éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬"
echo "================================"

# æ£€æŸ¥æ˜¯å¦ä»¥rootè¿è¡Œ
if [[ $EUID -eq 0 ]]; then
    echo "âš ï¸  ä¸å»ºè®®ä»¥rootç”¨æˆ·è¿è¡Œï¼Œè¯·ä½¿ç”¨æ™®é€šç”¨æˆ·"
    read -p "æ˜¯å¦ç»§ç»­? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# å‡½æ•°ï¼šæ‰“å°å¸¦é¢œè‰²çš„æ¶ˆæ¯
print_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

print_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# å‡½æ•°ï¼šæ£€æŸ¥å‘½ä»¤æ˜¯å¦å­˜åœ¨
check_command() {
    if ! command -v $1 &> /dev/null; then
        print_error "å‘½ä»¤ '$1' æœªæ‰¾åˆ°ï¼Œè¯·å…ˆå®‰è£…"
        exit 1
    fi
}

# æ£€æŸ¥å¿…éœ€çš„å‘½ä»¤
print_info "æ£€æŸ¥å¿…éœ€çš„å‘½ä»¤..."
check_command python3
check_command pip3
check_command docker
check_command docker-compose
check_command psql

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
BACKEND_DIR="$PROJECT_ROOT/backend"

print_info "é¡¹ç›®æ ¹ç›®å½•: $PROJECT_ROOT"

# 1. ç”Ÿæˆå®‰å…¨çš„SECRET_KEY
print_info "ç”Ÿæˆå®‰å…¨çš„SECRET_KEY..."
SECRET_KEY=$(python3 -c "import secrets; print(secrets.token_urlsafe(50))")
print_info "ç”Ÿæˆçš„SECRET_KEY: ${SECRET_KEY:0:20}..."

# 2. åˆ›å»ºç”Ÿäº§ç¯å¢ƒ.envæ–‡ä»¶
print_info "åˆ›å»ºç”Ÿäº§ç¯å¢ƒ.envæ–‡ä»¶..."
cat > "$BACKEND_DIR/.env.production" << EOF
# ========================================
# ScholarMind ç”Ÿäº§ç¯å¢ƒé…ç½®
# è‡ªåŠ¨ç”Ÿæˆäº $(date)
# ========================================

# Django Settings
SECRET_KEY=$SECRET_KEY
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com

# Database (PostgreSQL)
DB_NAME=scholarmind_prod
DB_USER=scholarmind_user
DB_PASSWORD=$(openssl rand -base64 32 | tr -d '/+=' | cut -c1-24)
DB_HOST=localhost
DB_PORT=5432

# Redis
REDIS_URL=redis://localhost:6379/1
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# CORS
CORS_ALLOWED_ORIGINS=https://your-domain.com,http://localhost:3000

# DeepSeek API (è¯·æ›¿æ¢ä¸ºå®é™…å€¼)
DEEPSEEK_API_KEY=your-actual-deepseek-api-key-here

# Email (SMTPé…ç½®)
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_HOST_USER=your-email@gmail.com
EMAIL_HOST_PASSWORD=your-app-password

# Logging
LOG_LEVEL=INFO

# æ–‡ä»¶ä¸Šä¼ é™åˆ¶ (MB)
FILE_UPLOAD_MAX_SIZE=50
DATA_UPLOAD_MAX_SIZE=50
EOF

print_info "ç”Ÿäº§ç¯å¢ƒé…ç½®æ–‡ä»¶å·²åˆ›å»º: $BACKEND_DIR/.env.production"

# 3. åˆ›å»ºæ•°æ®åº“è®¾ç½®è„šæœ¬
print_info "åˆ›å»ºæ•°æ®åº“åˆå§‹åŒ–è„šæœ¬..."
cat > "$PROJECT_ROOT/deploy/init_database.sql" << EOF
-- ScholarMind æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
-- è‡ªåŠ¨ç”Ÿæˆäº $(date)

-- åˆ›å»ºæ•°æ®åº“
CREATE DATABASE scholarmind_prod;

-- åˆ›å»ºç”¨æˆ·
CREATE USER scholarmind_user WITH PASSWORD '$(grep DB_PASSWORD "$BACKEND_DIR/.env.production" | cut -d= -f2)';

-- æˆäºˆæƒé™
GRANT ALL PRIVILEGES ON DATABASE scholarmind_prod TO scholarmind_user;

-- è®¾ç½®æ‰©å±• (å¦‚æœéœ€è¦)
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- åˆ›å»ºæµ‹è¯•æ•°æ®åº“
CREATE DATABASE scholarmind_test;
GRANT ALL PRIVILEGES ON DATABASE scholarmind_test TO scholarmind_user;

print_info "æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬å·²åˆ›å»º: $PROJECT_ROOT/deploy/init_database.sql"

# 4. åˆ›å»ºDocker Composeç”Ÿäº§é…ç½®æ–‡ä»¶
print_info "åˆ›å»ºDocker Composeç”Ÿäº§é…ç½®..."
cat > "$PROJECT_ROOT/docker-compose.prod.yml" << EOF
version: '3.8'

services:
  # PostgreSQLæ•°æ®åº“
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: scholarmind_prod
      POSTGRES_USER: scholarmind_user
      POSTGRES_PASSWORD: \${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./deploy/init_database.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scholarmind_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Djangoåç«¯ (Gunicorn)
  backend:
    build:
      context: ./backend
      dockerfile: ../docker/Dockerfile.backend.prod
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 4"
    volumes:
      - ./backend:/app
      - static_volume:/app/staticfiles
      - media_volume:/app/media
    ports:
      - "8000:8000"
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.production
      - DATABASE_URL=postgres://scholarmind_user:\${DB_PASSWORD}@db:5432/scholarmind_prod
      - REDIS_URL=redis://redis:6379/1
      - CELERY_BROKER_URL=redis://redis:6379/0
    env_file:
      - ./backend/.env.production
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # Celery Worker
  celery:
    build:
      context: ./backend
      dockerfile: ../docker/Dockerfile.backend.prod
    command: celery -A config worker -l info --concurrency=4
    volumes:
      - ./backend:/app
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.production
      - DATABASE_URL=postgres://scholarmind_user:\${DB_PASSWORD}@db:5432/scholarmind_prod
      - REDIS_URL=redis://redis:6379/1
      - CELERY_BROKER_URL=redis://redis:6379/0
    env_file:
      - ./backend/.env.production
    depends_on:
      - backend
      - redis
    restart: unless-stopped

  # Celery Beat (å®šæ—¶ä»»åŠ¡)
  celery-beat:
    build:
      context: ./backend
      dockerfile: ../docker/Dockerfile.backend.prod
    command: celery -A config beat -l info
    volumes:
      - ./backend:/app
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.production
      - DATABASE_URL=postgres://scholarmind_user:\${DB_PASSWORD}@db:5432/scholarmind_prod
      - REDIS_URL=redis://redis:6379/1
      - CELERY_BROKER_URL=redis://redis:6379/0
    env_file:
      - ./backend/.env.production
    depends_on:
      - backend
      - redis
    restart: unless-stopped

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf
      - static_volume:/static
      - media_volume:/media
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  static_volume:
  media_volume:
EOF

print_info "Docker Composeç”Ÿäº§é…ç½®å·²åˆ›å»º: $PROJECT_ROOT/docker-compose.prod.yml"

# 5. åˆ›å»ºç”Ÿäº§Dockerfile
print_info "åˆ›å»ºç”Ÿäº§Dockerfile..."
mkdir -p "$PROJECT_ROOT/docker"

cat > "$PROJECT_ROOT/docker/Dockerfile.backend.prod" << EOF
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    libpq-dev \
    gcc \
    libmagic1 \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements/production.txt .
RUN pip install --no-cache-dir -r production.txt

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# æ”¶é›†é™æ€æ–‡ä»¶ (åœ¨æ„å»ºæ—¶æ‰§è¡Œ)
RUN python manage.py collectstatic --noinput

EXPOSE 8000

CMD ["gunicorn", "config.wsgi:application", "--bind", "0.0.0.0:8000", "--workers", "4"]
EOF

# 6. åˆ›å»ºNginxé…ç½®
print_info "åˆ›å»ºNginxé…ç½®..."
mkdir -p "$PROJECT_ROOT/docker/nginx"

cat > "$PROJECT_ROOT/docker/nginx/nginx.conf" << EOF
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '\$remote_addr - \$remote_user [\$time_local] "\$request" '
                    '\$status \$body_bytes_sent "\$http_referer" '
                    '"\$http_user_agent" "\$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream backend {
        server backend:8000;
    }

    server {
        listen 80;
        server_name your-domain.com www.your-domain.com;
        return 301 https://\$server_name\$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name your-domain.com www.your-domain.com;

        # SSLè¯ä¹¦ (éœ€è¦æ›¿æ¢ä¸ºå®é™…è·¯å¾„)
        ssl_certificate /etc/ssl/certs/your-domain.crt;
        ssl_certificate_key /etc/ssl/private/your-domain.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;

        # é™æ€æ–‡ä»¶
        location /static/ {
            alias /static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # åª’ä½“æ–‡ä»¶
        location /media/ {
            alias /media/;
            expires 30d;
            add_header Cache-Control "public";
        }

        # APIè¯·æ±‚
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto \$scheme;
        }

        # WebSocketæ”¯æŒ
        location /ws/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade \$http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        }

        # å¥åº·æ£€æŸ¥
        location /health/ {
            proxy_pass http://backend;
            access_log off;
        }

        # ç®¡ç†åå°
        location /admin/ {
            proxy_pass http://backend;
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto \$scheme;
        }
    }
}
EOF

# 7. åˆ›å»ºéƒ¨ç½²æ£€æŸ¥è„šæœ¬
print_info "åˆ›å»ºéƒ¨ç½²æ£€æŸ¥è„šæœ¬..."
cat > "$PROJECT_ROOT/deploy/check_deployment.sh" << EOF
#!/bin/bash
# éƒ¨ç½²æ£€æŸ¥è„šæœ¬

set -e

echo "ğŸ” æ£€æŸ¥éƒ¨ç½²çŠ¶æ€..."

# æ£€æŸ¥DockeræœåŠ¡
echo "1. æ£€æŸ¥DockeræœåŠ¡..."
docker-compose -f docker-compose.prod.yml ps

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "2. æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
docker-compose -f docker-compose.prod.yml exec db pg_isready -U scholarmind_user

# æ£€æŸ¥Redisè¿æ¥
echo "3. æ£€æŸ¥Redisè¿æ¥..."
docker-compose -f docker-compose.prod.yml exec redis redis-cli ping

# æ£€æŸ¥Djangoå¥åº·ç«¯ç‚¹
echo "4. æ£€æŸ¥Djangoå¥åº·ç«¯ç‚¹..."
curl -f http://localhost:8000/api/health/ || echo "å¥åº·æ£€æŸ¥å¤±è´¥"

# æ£€æŸ¥é™æ€æ–‡ä»¶
echo "5. æ£€æŸ¥é™æ€æ–‡ä»¶..."
docker-compose -f docker-compose.prod.yml exec backend ls -la /app/staticfiles/

echo "âœ… éƒ¨ç½²æ£€æŸ¥å®Œæˆ"
EOF

chmod +x "$PROJECT_ROOT/deploy/check_deployment.sh"

# 8. åˆ›å»ºä¸€é”®éƒ¨ç½²è„šæœ¬
print_info "åˆ›å»ºä¸€é”®éƒ¨ç½²è„šæœ¬..."
cat > "$PROJECT_ROOT/deploy/deploy.sh" << EOF
#!/bin/bash
# ScholarMind ä¸€é”®éƒ¨ç½²è„šæœ¬

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½² ScholarMind..."

# 1. åœæ­¢ç°æœ‰æœåŠ¡
echo "1. åœæ­¢ç°æœ‰æœåŠ¡..."
docker-compose -f docker-compose.prod.yml down || true

# 2. æ„å»ºé•œåƒ
echo "2. æ„å»ºé•œåƒ..."
docker-compose -f docker-compose.prod.yml build

# 3. å¯åŠ¨æœåŠ¡
echo "3. å¯åŠ¨æœåŠ¡..."
docker-compose -f docker-compose.prod.yml up -d

# 4. ç­‰å¾…æœåŠ¡å°±ç»ª
echo "4. ç­‰å¾…æœåŠ¡å°±ç»ª..."
sleep 10

# 5. è¿è¡Œæ•°æ®åº“è¿ç§»
echo "5. è¿è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose -f docker-compose.prod.yml exec backend python manage.py migrate

# 6. åˆ›å»ºè¶…çº§ç”¨æˆ· (å¯é€‰)
echo "6. åˆ›å»ºè¶…çº§ç”¨æˆ·..."
read -p "æ˜¯å¦åˆ›å»ºè¶…çº§ç”¨æˆ·? (y/N): " -n 1 -r
echo
if [[ \$REPLY =~ ^[Yy]$ ]]; then
    docker-compose -f docker-compose.prod.yml exec backend python manage.py createsuperuser
fi

# 7. è¿è¡Œéƒ¨ç½²æ£€æŸ¥
echo "7. è¿è¡Œéƒ¨ç½²æ£€æŸ¥..."
./deploy/check_deployment.sh

echo "ğŸ‰ éƒ¨ç½²å®Œæˆ!"
echo "ğŸŒ è®¿é—®åœ°å€: http://localhost:8000"
echo "ğŸ”§ ç®¡ç†åå°: http://localhost:8000/admin/"
echo "ğŸ“Š æŸ¥çœ‹æ—¥å¿—: docker-compose -f docker-compose.prod.yml logs -f"
EOF

chmod +x "$PROJECT_ROOT/deploy/deploy.sh"

# 9. åˆ›å»ºå¤‡ä»½è„šæœ¬
print_info "åˆ›å»ºæ•°æ®åº“å¤‡ä»½è„šæœ¬..."
cat > "$PROJECT_ROOT/deploy/backup.sh" << EOF
#!/bin/bash
# æ•°æ®åº“å¤‡ä»½è„šæœ¬

set -e

BACKUP_DIR="\$HOME/scholarmind_backups"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\$BACKUP_DIR/scholarmind_backup_\$TIMESTAMP.sql"

mkdir -p "\$BACKUP_DIR"

echo "ğŸ“¦ å¤‡ä»½æ•°æ®åº“åˆ°: \$BACKUP_FILE"

docker-compose -f docker-compose.prod.yml exec db pg_dump -U scholarmind_user scholarmind_prod > "\$BACKUP_FILE"

# å‹ç¼©å¤‡ä»½
gzip "\$BACKUP_FILE"

echo "âœ… å¤‡ä»½å®Œæˆ: \${BACKUP_FILE}.gz"

# åˆ é™¤7å¤©å‰çš„å¤‡ä»½
find "\$BACKUP_DIR" -name "*.gz" -mtime +7 -delete
EOF

chmod +x "$PROJECT_ROOT/deploy/backup.sh"

# è®¾ç½®è„šæœ¬æƒé™
chmod +x "$PROJECT_ROOT/deploy/setup.sh"

print_info "ğŸ‰ éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬åˆ›å»ºå®Œæˆ!"
echo ""
echo "ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:"
echo "1. ç¼–è¾‘ $BACKEND_DIR/.env.production æ–‡ä»¶ï¼Œå¡«å†™å®é™…é…ç½®"
echo "2. è¿è¡Œ ./deploy/deploy.sh å¼€å§‹éƒ¨ç½²"
echo "3. è¿è¡Œ ./deploy/check_deployment.sh æ£€æŸ¥éƒ¨ç½²çŠ¶æ€"
echo ""
echo "ğŸ”§ å¯ç”¨è„šæœ¬:"
echo "  ./deploy/setup.sh      - ç”Ÿæˆé…ç½®æ–‡ä»¶ (å·²è¿è¡Œ)"
echo "  ./deploy/deploy.sh     - ä¸€é”®éƒ¨ç½²"
echo "  ./deploy/check_deployment.sh - æ£€æŸ¥éƒ¨ç½²"
echo "  ./deploy/backup.sh     - æ•°æ®åº“å¤‡ä»½"
echo ""
echo "âš ï¸  æ³¨æ„:"
echo "  - è¯·ç¡®ä¿å·²å®‰è£… Docker å’Œ Docker Compose"
echo "  - ç”Ÿäº§ç¯å¢ƒè¯·ä½¿ç”¨çœŸå®çš„ SSL è¯ä¹¦"
echo "  - å®šæœŸè¿è¡Œå¤‡ä»½è„šæœ¬"